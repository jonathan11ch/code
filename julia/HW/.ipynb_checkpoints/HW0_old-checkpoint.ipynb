{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW0 \n",
    "## Jonathan Casas\n",
    "### SUID: 821280044"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single neuron will be implemented to perform function approximation of the following expression:\n",
    "    $$f(x)=-8x+3,$$\n",
    "implemented as\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "actual (generic function with 1 method)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual(x) = -8x + 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train and test the NN, the following data is generated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3 -5 … -39989 -39997], [-47997; -48005; … ; -51989; -51997])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test = hcat(0:5000...), hcat(6000:6500)\n",
    "y_train, y_test = actual.(x_train), actual.(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Model\n",
    "The model is designed to be a single neuron with single input and single output. In order to implement the model, the library FLux is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense(1, 1)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux\n",
    "predict = Dense(1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function and Optimization algorithm\n",
    "\n",
    "The loss function used will be the standard Mean-Square Erros (mse) and the optimization algorithm is the gradient descendent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Learning with different dataset size\n",
    "In order to compare the learning time, three data sets will be defined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Tuple{Array{Int64,2},Array{Int64,2}},1}:\n",
       " ([0 1 … 998 999], [3 -5 … -7981 -7989])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = [(hcat(x_train[1:10]...), hcat(y_train[1:10]...))]\n",
    "data2 = [(hcat(x_train[1:100]...), hcat(y_train[1:100]...))]\n",
    "data3 = [(hcat(x_train[1:1000]...), hcat(y_train[1:1000]...))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, the predict model will be cloned to have similar initial conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense(1, 1)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict1 = deepcopy(predict)\n",
    "predict2 = deepcopy(predict)\n",
    "predict3 = deepcopy(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Descent(1.0e-5)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loss function\n",
    "loss1(x,y) = Flux.Losses.mse(predict1(x), y)\n",
    "loss2(x,y) = Flux.Losses.mse(predict2(x), y)\n",
    "loss3(x,y) = Flux.Losses.mse(predict3(x), y)\n",
    "#optimization algorithm\n",
    "opt = Descent(0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params([Float32[1.5222082], Float32[0.0]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter1 = Flux.params(predict1)\n",
    "parameter2 = Flux.params(predict2)\n",
    "parameter3 = Flux.params(predict3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Learning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iterative_learning3 (generic function with 1 method)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux.Optimise: train!\n",
    "function iterative_learning1()\n",
    "    #while loss(x,y) > epsilon\n",
    "    for epoch in 1:1000\n",
    "        train!(loss1, parameter1, data1, opt)\n",
    "        #println(loss(hcat(x_train[1:10]...),hcat(y_train[1:10]...)))\n",
    "\n",
    "    end\n",
    "    \n",
    "end\n",
    "    \n",
    "function iterative_learning2()\n",
    "    #while loss(x,y) > epsilon\n",
    "    for epoch in 1:1000\n",
    "        train!(loss2, parameter2, data2, opt)\n",
    "        #println(loss(hcat(x_train[1:10]...),hcat(y_train[1:10]...)))\n",
    "\n",
    "    end\n",
    "    \n",
    "end\n",
    "    \n",
    "function iterative_learning3()\n",
    "    #while loss(x,y) > epsilon\n",
    "    for epoch in 1:1000\n",
    "        train!(loss3, parameter3, data3, opt)\n",
    "        #println(loss(hcat(x_train[1:10]...),hcat(y_train[1:10]...)))\n",
    "\n",
    "    end\n",
    "    \n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2336.0652\n",
      "  0.113655 seconds (226.67 k allocations: 10.496 MiB)\n",
      "729.5412\n"
     ]
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "println(loss1(hcat(x_train[1:10]...),hcat(y_train[1:10]...)))\n",
    "@time iterative_learning1()\n",
    "println(loss1(hcat(x_train[1:10]...),hcat(y_train[1:10]...)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294903.9\n",
      "  0.118345 seconds (230.67 k allocations: 13.868 MiB)\n",
      "2.4812868\n"
     ]
    }
   ],
   "source": [
    "println(loss2(hcat(x_train[1:100]...),hcat(y_train[1:100]...)))\n",
    "@time iterative_learning2()\n",
    "println(loss2(hcat(x_train[1:100]...),hcat(y_train[1:100]...)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0150298e7\n",
      "  0.207117 seconds (230.67 k allocations: 45.316 MiB, 7.92% gc time)\n",
      "NaN\n"
     ]
    }
   ],
   "source": [
    "println(loss3(hcat(x_train[1:1000]...),hcat(y_train[1:1000]...)))\n",
    "@time iterative_learning3()\n",
    "println(loss3(hcat(x_train[1:1000]...),hcat(y_train[1:1000]...)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
