{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "actual (generic function with 1 method)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual(x) = -8x + 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train and test the NN, the following data is generated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3.0 2.9999992 … -36.9999992 -37.0], [-47997; -48005; … ; -51989; -51997])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train1, x_test1 = hcat(0:1:5...), hcat(6000:6500)\n",
    "x_train2, x_test2 = hcat(0:0.1:5...), hcat(6000:6500)\n",
    "x_train3, x_test3 = hcat(0:0.001:5...), hcat(6000:6500)\n",
    "x_train4, x_test4 = hcat(0:0.0000001:5...), hcat(6000:6500)\n",
    "\n",
    "y_train1, y_test1 = actual.(x_train1), actual.(x_test1)\n",
    "y_train2, y_test2 = actual.(x_train2), actual.(x_test2)\n",
    "y_train3, y_test3 = actual.(x_train3), actual.(x_test3)\n",
    "y_train4, y_test4 = actual.(x_train4), actual.(x_test4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Model\n",
    "The model is designed to be a single neuron with single input and single output. In order to implement the model, the library FLux is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense(1, 1)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux\n",
    "predict = Dense(1,1)"
   ]
  },
  {
   "cell_type": "markdown",
>>>>>>> fc8e7f1a1f2dae6cdc01062ec93aa58b3e43e6a4
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "begin\n",
    "    #import Pkg;\n",
    "    #packages = [\"CSV\",\"DataFrames\",\"PlutoUI\",\"Plots\",\"Combinatorics\"]   \n",
    "    #Pkg.add(packages)\n",
    "\n",
    "    using CSV, DataFrames, PlutoUI, Plots, Combinatorics\n",
    "\n",
    "    #plotly()\n",
    "    #theme(:solarized_light)\n",
    "end\n",
    "\n",
    "\n",
    "begin\n",
    "    path = \"/home/jonathan/Datasets/iris.data\"\n",
    "    csv_data = CSV.File(path, header=false)\n",
    "    y  =  vcat(-(ones(50)),ones(50),-(ones(50)))\n",
    "    iris_names = [\"sepal_len\", \"sepal_wid\", \"petal_len\", \"petal_wid\", \"output\",\"class\"]\n",
    "    df = DataFrame([csv_data.Column1,csv_data.Column2,csv_data.Column3,csv_data.Column4,y,csv_data.Column5], Symbol.(iris_names))\n",
    "    dropmissing!(df)\n",
    "\n",
    "end\n",
    "\n",
    "#begin\n",
    "#    df_species = groupby(df, :class)\n",
    "#end\n",
    "\n",
    "#df_species[3]\n",
    "\n",
    "#begin\n",
    "#    scatter(title=\"len vs wid\", xlabel = \"length\", ylabel=\"width\",\n",
    "#             df.sepal_len, df.sepal_wid, color=\"blue\", label=\"sepal\")\n",
    "#    scatter!(df.petal_len, df.petal_wid, color=\"red\", label=\"petal\")\n",
    "#end\n",
    "\n",
    "begin\n",
    "    #Pkg.add(\"Flux\")\n",
    "    #Pkg.add(\"CUDA\")\n",
    "    #Pkg.add(\"IterTools\")\n",
    "\n",
    "    using Flux\n",
    "    using Flux: Data.DataLoader\n",
    "    #using Flux: @epochs\n",
    "    #using CUDA\n",
    "    using Random\n",
    "    using IterTools: ncycle\n",
    "\n",
    "    Random.seed!(123);\n",
    "end\n",
    "\n",
    "begin   \n",
    "    # Convert df to array\n",
    "    data = Matrix(df)\n",
    "\n",
    "    # Shuffle\n",
    "    data = data[shuffle(1:end), :]\n",
    "\n",
    "    # train/test split\n",
    "    train_test_ratio = .7\n",
    "    idx = Int(floor(size(df, 1) * train_test_ratio))\n",
    "    data_train = data[1:idx,:]\n",
    "    data_test = data[idx+1:end, :]\n",
    "    \n",
    "    tuple_train = []\n",
    "    tuple_test = []\n",
    "    \n",
    "    #tuple_convert(d::Array) = (d[:,1:4], d[:,5])\n",
    "    for d = 1: size(data_train)[1]\n",
    "        append!(tuple_train, [(data_train[d,1:4],data_train[d,5])])\n",
    "    end\n",
    "    for d = 1:size(data_test)[1]\n",
    "        append!(tuple_test, [(data_test[d,1:4],data_test[d,5])])\n",
    "    end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron Model"
=======
    "## Iterative Learning with different dataset size\n",
    "In order to compare the learning time, three data sets will be defined\n"
>>>>>>> fc8e7f1a1f2dae6cdc01062ec93aa58b3e43e6a4
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 212,
=======
   "execution_count": 118,
>>>>>>> fc8e7f1a1f2dae6cdc01062ec93aa58b3e43e6a4
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "update_w! (generic function with 2 methods)"
      ]
     },
     "execution_count": 212,
=======
       "1-element Array{Tuple{Array{Float64,2},Array{Float64,2}},1}:\n",
       " ([0.0 0.001 … 4.999 5.0], [3.0 2.992 … -36.992 -37.0])"
      ]
     },
     "execution_count": 118,
>>>>>>> fc8e7f1a1f2dae6cdc01062ec93aa58b3e43e6a4
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "#Function Like Objects\n",
    "struct Perceptron{T}\n",
    "    W::Vector{T}\n",
    "    sigma\n",
    "end\n",
    "function (p::Perceptron)(x::Vector)\n",
    "    return p.sigma(p.W'*x) \n",
    "end\n",
    "\n",
    "mutable struct PerceptronOpt\n",
    "    eta::Real\n",
    "end\n",
    "\n",
    "\n",
    "p = Perceptron{Real}(rand(4),x->sign(x))\n",
    "\n",
    "opt = PerceptronOpt(1)\n",
    "\n",
    "\n",
    "function update_w!(p::Perceptron,opt,data::Array)\n",
    "    for d in data\n",
    "        x = d[1]\n",
    "        y = d[2]\n",
    "        for i = 1:length(p.W)\n",
    "            p.W[i]= p.W[i] + opt.eta*(y- p(x))*x[i]\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n"
=======
    "data1 = [(x_train1, y_train1)]\n",
    "data2 = [(x_train2, y_train2)]\n",
    "data3 = [(x_train3, y_train3)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, the predict model will be cloned to have similar initial conditions"
>>>>>>> fc8e7f1a1f2dae6cdc01062ec93aa58b3e43e6a4
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p.W = Real[-1.7410095449802667, 1.625650706845518, 0.08451502571605762, 0.4614822995880308]\n",
      "p(d[1]) = -1.0\n",
      "x = d[1] = Any[6.7, 3.3, 5.7, 2.1]\n",
      "y = d[2] = -1.0\n",
      "p.W = Real[-1.7410095449802667, 1.625650706845518, 0.08451502571605762, 0.4614822995880308]\n",
      "p(d[1]) = -1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 207,
=======
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense(1, 1)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict1 = deepcopy(predict)\n",
    "predict2 = deepcopy(predict)\n",
    "predict3 = deepcopy(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function and Optimization algorithm\n",
    "\n",
    "The loss function used will be the standard Mean-Square Erros (mse) and the optimization algorithm is the gradient descendent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Descent(0.1)"
      ]
     },
     "execution_count": 120,
>>>>>>> fc8e7f1a1f2dae6cdc01062ec93aa58b3e43e6a4
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "#test\n",
    "d = tuple_train[1]\n",
    "@show p.W\n",
    "@show p(d[1])\n",
    "update_w!(p,opt,[d])\n",
    "@show p.W\n",
    "@show p(d[1])"
=======
    "#loss function\n",
    "loss1(x,y) = Flux.Losses.mse(predict1(x), y)\n",
    "loss2(x,y) = Flux.Losses.mse(predict2(x), y)\n",
    "loss3(x,y) = Flux.Losses.mse(predict3(x), y)\n",
    "#optimization algorithm\n",
    "opt = Descent(0.1)"
>>>>>>> fc8e7f1a1f2dae6cdc01062ec93aa58b3e43e6a4
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p.W = Real[0.7530361910318599, 0.734625171895988, 0.48374511338226545, 0.37414220887867367]\n",
      "p.W = Real[-0.9869638089681401, 0.37462517189598776, 0.48374511338226545, 0.37414220887867367]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4-element Array{Real,1}:\n",
       " -0.9869638089681401\n",
       "  0.37462517189598776\n",
       "  0.48374511338226545\n",
       "  0.37414220887867367"
      ]
     },
     "execution_count": 213,
=======
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params([Float32[-0.89934945], Float32[0.0]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter1 = Flux.params(predict1)\n",
    "parameter2 = Flux.params(predict2)\n",
    "parameter3 = Flux.params(predict3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Learning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iterative_learning3 (generic function with 2 methods)"
      ]
     },
     "execution_count": 122,
>>>>>>> fc8e7f1a1f2dae6cdc01062ec93aa58b3e43e6a4
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "@show p.W\n",
    "update_w!(p,opt,tuple_train)\n",
    "@show p.W"
=======
    "using Flux.Optimise: train!\n",
    "function iterative_learning1(epsilon = 1)\n",
    "    #while loss(x,y) > epsilon\n",
    "    while loss1(x_train1,y_train1) > epsilon\n",
    "        train!(loss1, parameter1, data1, opt)\n",
    "        #println(loss(hcat(x_train[1:10]...),hcat(y_train[1:10]...)))\n",
    "\n",
    "    end\n",
    "    \n",
    "end\n",
    "    \n",
    "function iterative_learning2(epsilon = 1)\n",
    "    #while loss(x,y) > epsilon\n",
    "     while loss2(x_train2,y_train2) > epsilon\n",
    "        train!(loss2, parameter2, data2, opt)\n",
    "        #println(loss(hcat(x_train[1:10]...),hcat(y_train[1:10]...)))\n",
    "\n",
    "    end\n",
    "    \n",
    "end\n",
    "    \n",
    "function iterative_learning3(epsilon = 1)\n",
    "    #while loss(x,y) > epsilon\n",
    "     while loss3(x_train3,y_train3) > epsilon\n",
    "        train!(loss3, parameter3, data3, opt)\n",
    "        #println(loss(hcat(x_train[1:10]...),hcat(y_train[1:10]...)))\n",
    "\n",
    "    end\n",
    "    \n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364.66663\n",
      "  0.071128 seconds (134.39 k allocations: 6.563 MiB)\n",
      "0.98191214\n"
     ]
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "println(loss1(x_train1,y_train1))\n",
    "@time iterative_learning1()\n",
    "println(loss1(x_train1,y_train1))\n",
    "\n",
    "\n"
>>>>>>> fc8e7f1a1f2dae6cdc01062ec93aa58b3e43e6a4
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 214,
=======
   "execution_count": 124,
>>>>>>> fc8e7f1a1f2dae6cdc01062ec93aa58b3e43e6a4
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 2.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 2.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 2.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 2.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 2.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 2.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 2.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 2.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 2.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 2.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 2.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 2.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 2.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 2.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n",
      "(tuple_test[n])[2] - p((tuple_test[n])[1]) = 0.0\n"
=======
      "326.85216485737516\n",
      "  0.057053 seconds (111.87 k allocations: 5.530 MiB)\n",
      "0.9317928283953703\n"
>>>>>>> fc8e7f1a1f2dae6cdc01062ec93aa58b3e43e6a4
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "for n = 1:length(tuple_test)[1]\n",
    "    @show tuple_test[n][2] - p(tuple_test[n][1])    \n",
    "end"
=======
    "println(loss2(x_train2,y_train2))\n",
    "@time iterative_learning2()\n",
    "println(loss2(x_train2,y_train2))\n"
>>>>>>> fc8e7f1a1f2dae6cdc01062ec93aa58b3e43e6a4
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 208,
=======
   "execution_count": 125,
>>>>>>> fc8e7f1a1f2dae6cdc01062ec93aa58b3e43e6a4
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 2.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n",
      "(tuple_train[n])[2] - p((tuple_train[n])[1]) = 0.0\n"
=======
      "322.69257627120794\n",
      "  0.088879 seconds (606.79 k allocations: 23.372 MiB)\n",
      "0.9830640093110259\n"
>>>>>>> fc8e7f1a1f2dae6cdc01062ec93aa58b3e43e6a4
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "for n = 1:length(tuple_train)[1]\n",
    "    @show tuple_train[n][2] - p(tuple_train[n][1])    \n",
    "end"
=======
    "println(loss3(x_train3,y_train3))\n",
    "@time iterative_learning3()\n",
    "println(loss3(x_train3,y_train3))\n"
>>>>>>> fc8e7f1a1f2dae6cdc01062ec93aa58b3e43e6a4
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
